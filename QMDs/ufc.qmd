---
title: "UFC Champ predictions"
date: 2026-01-15
format: html
jupyter: python3
---
This dataset contains information on UFC fights that had a champion participating. This dataset is 4 years old so what I would like to do is create a model, perhaps a simple one, that will be used to predict championship title matches that have happened since and upcoming bouts. To challenge myself further I wil try to make **USEFUL** vizualizations and will be using python to throughout this project including using new packages such as matplotlib, seaborn and plotly (I have minimial experience with pandas).

First lets load in these packages and our [UFC dataset](https://www.kaggle.com/datasets/akouaorsot/ufc-champions-fights/data) from kaggle and take a look at some of the first rows of the dataset

```{python}
import os
import pandas as pd
base_dir = os.path.dirname(os.path.abspath("__file__"))
data_path = os.path.join(base_dir, "..", "data", "ufc_champs_final.csv")
ufc = pd.read_csv(data_path)
import matplotlib.pyplot as plt
import seaborn as sns
import plotly.express as px
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, classification_report
print(ufc.head())
```

```{python}
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, classification_report
```
As we can see there are a 121 variables so we need to consider whether there are variables that are unnecessary for our purposes such as significant strikes as we are going to use our model to try and predict future title bouts and until the bout is over we do not know these quantites. First lets take a look at the counts of NAs in each variable in descending order, this is implemented in the following code chunk:

```{python}
na_counts = ufc.isna().sum().sort_values(ascending=False)
print(na_counts)
```

As we can see there are numerous variables that have considerable missing data especially these columns defining one of the fighters respective rank during the dates of the bouts which makes sense as each fighter that is not a champion at the time of the respective bout will only have 1 rank in 1 weight class (out of 12). Notice we have a weightclass column so can we collapse the ranks into 1 column that gives their rank and we already would know their weightclass from the weightclass column. Luckily I just noticed there is a column that already does this so we can drop 24 variables, but if there was no column that did this we would be able to use python's version of pivot longer with the melt function collapsing the columns into one after filtering them with some form of regular expression. 

```{python}
#| eval: false
ufc_subset_drop = ufc.filter(regex="_rank")
ufc_subset_drop = ufc_subset_drop.drop(columns = ["B_match_weightclass_rank", "R_match_weightclass_rank", "B_Pound-for-Pound_rank", "better_rank", "R_Pound-for-Pound_rank"]) 
ufc_subset_keep = [f for f in ufc if f not in ufc_subset_drop]
#With the code above we have a subset that has selected the 24 columns of interest

 ufc_subset = ufc.melt(id_vars = ufc_subset_keep,
                    value_cars = ufc_subset_keep,
                    var_name = "weight_class_rank",
                    value_name = "rank")
```

The code above is an implementation of using the melt function for the purpose stated above. Instead we can just drop the 24 variables as shown in the following code chunk. Now we have 97 variables. 

```{python}
ufc_subset_drop = ufc.filter(regex="_rank")
ufc_subset_drop = ufc_subset_drop.drop(columns = ["B_match_weightclass_rank", "R_match_weightclass_rank", "B_Pound-for-Pound_rank", "better_rank", "R_Pound-for-Pound_rank"]) 
ufc_cleaned_data = ufc.drop(columns= ufc_subset_drop)

```

97 variables is still a lot lets take a look to see if there are variables that will not be useful for out purposes, first lets take a look if there are variables that we will not be able to implement before the fight results. As we can see there are columns such as the round that the winner finished their opponent, the time of the finish, as well with the details of the finish.
```{python}
ufc_cleaned_data = ufc_cleaned_data.drop(columns = ["total_fight_time_secs", "finish_round_time", "finish_round", "finish_details", "finish", "R_win_by_TKO_Doctor_Stoppage", "B_win_by_TKO_Doctor_Stoppage"])
```

Another step we can take to reduce the amount of variables for our model is to drop columns that cannot be quantified or add any sort of information for our model such as the date of the event, the row id, R_ev, and B_ev. I also misunderstood a column as I believed this dataset had a column for each fighter's ethnicity or place of birth which would be important since we have information on where the fight was held which might reveal if home-field advantage is important but turns out there is only information where the fight is held not on the individual fighter's place of birth or ethnicity and I do not think it is feasible to add every single fighters date of birth or ethnicity so I made the decision to drop these columns as they will only add noise.

```{python}
ufc_cleaned_data = ufc_cleaned_data.drop(columns = ["R_ev", "B_ev", "date", "Unnamed: 0", "empty_arena", "country", "location"])
```

There also seems to be redundant data (multicolinearity), for example we have information on the reach of both fighters, which is most likely important, but we also have a column dedicated to telling us the reach difference so it is easy to see the redundnacy, another example is the individual weights of the fighters as they fight at the same weight class so we know they are already at the same weight. I also find it important to notice that there might be data that seems redundant but there might be good reasons to keep the variable and in this dataset it corresponds to the individual ages of the fighters and the weight difference because for example the columns that has the weight difference treats all 5 year age differences the same which is not the case in athletic sports for instance there is a big difference between a 27 year old fighting a 32 year old (both in their physical primes) and a 32 year old fighting a 37 year old (one in his prime the other years outside their prime). In the following code cell I display all variables that contain "_dif" and from there I will make the decision whether to drop the "dif" column or the corresponding columns it is related to.

```{python}
ufc_diff_subset = ufc.filter(regex = '_dif')
print(ufc_diff_subset.head())
ufc_cleaned_data = ufc_cleaned_data.assign(sig_str_pct_diff = ufc_cleaned_data["R_avg_SIG_STR_pct"] - ufc_cleaned_data["B_avg_SIG_STR_pct"])
ufc_cleaned_data = ufc_cleaned_data.assign(td_pct_diff = ufc_cleaned_data["R_avg_TD_pct"] - ufc_cleaned_data["B_avg_TD_pct"])
ufc_cleaned_data = ufc_cleaned_data.drop(columns = ["B_current_lose_streak", "R_current_lose_streak", "B_current_win_streak", "R_current_win_streak", "B_draw", "R_draw", "B_avg_SIG_STR_landed", "R_avg_SIG_STR_landed", "B_avg_SIG_STR_pct", "R_avg_SIG_STR_pct", "B_avg_SUB_ATT", "R_avg_SUB_ATT", "B_avg_TD_landed", "R_avg_TD_landed", "B_longest_win_streak", "R_longest_win_streak", "B_losses", "R_losses", "B_total_rounds_fought", "R_total_rounds_fought", "B_total_title_bouts", "R_total_title_bouts", "B_win_by_Decision_Majority", "R_win_by_Decision_Majority", "B_Height_cms", "R_Height_cms", "B_Reach_cms", "R_Reach_cms"])
```

As we can see we are now at 57 variables and I was struggling what to do with all of these betting odds and after doing some research I believe that it would be more beneficial for me to take them out as I would like to base the model off of physicial attributes and past performence, and if I keep these betting odds this model can just become a reflection of those odds so in this next code cell I will remove them.

```{python}
ufc_clean_data = ufc_cleaned_data.drop(columns = ["R_odds", "B_odds", "r_dec_odds", "b_dec_odds", "r_sub_odds", "b_sub_odds", "r_ko_odds", "b_ko_odds"])
```

Now we are down to 49 columns and looking at a list of the columns I believe that there are no variables that need to be dropped. Something we now need to do is to decide whether or not to drop non-championship bouts so what I am going to do is create a copy of the dataset one that has only the championship fights and the other the total dataset up to this point. But first lets create a vizualization that shows us championship vs non-championship bouts.
```{python}
sns.set_theme(style = "whitegrid")
plt.figure(figsize = (8, 5))
ax = sns.countplot(data = ufc, x = "title_bout", palette = "viridis")
ax.set_xticklabels(['Non-Championship', 'Championship'])
plt.title("non-title vs title fights")
plt.xlabel("distribution of non-title vs title fights")
plt.ylabel("number of fights")
plt.show()
```

As we can see the majority of the data is Non-Championship data so for that reason I want to create two datasets as stated prior one that has all observations and the other only championship bouts.

```{python}
ufc_clean_total = ufc_clean_data
ufc_clean_champ_only = ufc_clean_data[ufc_clean_data["title_bout"]]
```

Now we can fit a simple model first so I would like to start with a logistic regression model in which we first have to transform our variable that we are trying to predict (Winner) into 1s and 0s from "Red" and "Blue" respectfully. Since we are using a logistic regression model we can only use numeric predictors and cannot have and NaNs in the data set so we need to prep our data.

```{python}
# Here we create a copy of the cleaned dataset
ufc_clean_log = ufc_clean_champ_only.copy() 
#Here we conver our target variable into 1s and 0s
ufc_clean_log['target'] = ufc_clean_log['Winner'].map({'Red': 1, 'Blue': 0})
#Here we extract only numeric columns
features_log = ufc_clean_log.select_dtypes(include=['number'])
#Here we filter so columns have no missing values phfilll check run head on this
features_log = [col for col in features_log.columns 
                if ufc_clean_log[col].isna().sum() == 0 and col != 'target']
model_df = ufc_clean_log[features_log + ['target']].dropna()
#Here we split the data into predictors and our target variable
x = model_df[features_log]
y = model_df['target']
#Here we split the data and fit the logistic regression model on the training set
x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)
model_fit = LogisticRegression(max_iter=1000) 
model_fit.fit(x_train, y_train)
#here we test the model on the test set (unseen data)
y_preds = model_fit.predict(x_test)
print(accuracy_score(y_test, y_preds))
```

Lets see how our model performs on some championship bouts that have happened since the last update of this dataset. We have to make a new observation for the bout in question and use our model to predict the outcome. Since it would be very tedious to get every stat needed for a new observation I decided to use AI to retrieve them. This new observation is a fight that happened Jan 24 in which Gaethje won.

```{python}
import pandas as pd

# Creating the stats for Gaethje (Red) vs Pimblett (Blue)
new_fight_stats = {
    'no_of_rounds': [5],
    'B_win_by_Decision_Split': [0],
    'B_win_by_Decision_Unanimous': [6],
    'B_win_by_KO/TKO': [7],
    'B_win_by_Submission': [10],
    'B_wins': [23],
    'B_Weight_lbs': [155],
    'R_win_by_Decision_Split': [1],
    'R_win_by_Decision_Unanimous': [5],
    'R_win_by_KO/TKO': [20],
    'R_win_by_Submission': [1],
    'R_wins': [27],
    'R_Weight_lbs': [155],
    'R_age': [37],
    'B_age': [31],
    'lose_streak_dif': [0], # Both coming off wins
    'win_streak_dif': [-6], # Paddy had a longer streak (7 vs 1)
    'longest_win_streak_dif': [2], # Gaethje's peak vs Paddy's
    'win_dif': [4],
    'loss_dif': [1],
    'total_round_dif': [30], # Gaethje has much more cage time
    'total_title_bout_dif': [6], # Paddy has never been in a UFC title bout
    'ko_dif': [13],
    'sub_dif': [-9],
    'height_dif': [1], # 5'11 vs 5'10
    'reach_dif': [-3], # Paddy has a reach advantage (73 vs 70)
    'age_dif': [6],
    'sig_str_dif': [1.4], # 6.59 vs 5.19
    'avg_sub_att_dif': [-1.7],
    'avg_td_dif': [-0.86],
    'constant_1': [1]
}

# Create the observation
X_new = pd.DataFrame(new_fight_stats)

# --- THE PREDICTION ---
# 1. Who does the model pick?
fight_prediction = model_fit.predict(X_new)
winner_label = "RED (Gaethje)" if fight_prediction[0] == 1 else "BLUE (Pimblett)"

# 2. How confident is it?
probs = model_fit.predict_proba(X_new)
confidence = probs[0][1] if fight_prediction[0] == 1 else probs[0][0]

print(f"Predicted Winner: {winner_label}")
print(f"Model Confidence: {confidence:.2%}")
```

Our model was right!!! lets try another and I am feeling like our model is performing a little too good lets look at a fight considered the greatest upset in UFC history Adesanya vs. Strickland (Adesanya was a heavy favorite)

```{python}
import pandas as pd

# Stats for Sean Strickland (Red) vs Israel Adesanya (Blue) - UFC 293
strickland_vs_izzy = {
    'no_of_rounds': [5],
    'B_win_by_Decision_Split': [0],
    'B_win_by_Decision_Unanimous': [6],
    'B_win_by_KO/TKO': [15],
    'B_win_by_Submission': [0],
    'B_wins': [24],
    'B_Weight_lbs': [185],
    'R_win_by_Decision_Split': [2],
    'R_win_by_Decision_Unanimous': [10],
    'R_win_by_KO/TKO': [11],
    'R_win_by_Submission': [4],
    'R_wins': [27],
    'R_Weight_lbs': [185],
    'R_age': [32],
    'B_age': [34],
    'lose_streak_dif': [0],
    'win_streak_dif': [1],   # Strickland was on 2-win streak, Izzy on 1
    'longest_win_streak_dif': [-1], 
    'win_dif': [3],
    'loss_dif': [3],         # Strickland had 5 losses, Izzy had 2
    'total_round_dif': [8],  # Strickland had more total rounds in MMA
    'total_title_bout_dif': [-10], # Huge gap: Izzy had 10 title bouts, Sean had 0
    'ko_dif': [-4],
    'sub_dif': [4],
    'height_dif': [-3],      # 6'1 vs 6'4
    'reach_dif': [-4],       # 76" vs 80"
    'age_dif': [-2],
    'sig_str_dif': [1.92],   # 5.86 landed/min vs 3.94 landed/min
    'avg_sub_att_dif': [0.2],
    'avg_td_dif': [0.94],    # 1.00 vs 0.06
    'constant_1': [1]
}

X_strickland = pd.DataFrame(strickland_vs_izzy)

# Run the prediction
prob = model_fit.predict_proba(X_strickland)
print(f"Strickland Win Probability: {prob[0][1]:.2%}")
print(f"Adesanya Win Probability: {prob[0][0]:.2%}")
```

As we can see our model predicted that there was over a 99% chance that Adesanya won which shows why this was such a great upset. It displays how it is hard to quantify a wildcard aspect to bouts.

Lets check a toss up fight Strickland vs Du Plessis(odds around -115 and -105)

```{python}
import pandas as pd

# Stats for Sean Strickland (Red) vs Dricus Du Plessis (Blue) - UFC 297
strickland_vs_dricus = {
    'no_of_rounds': [5],
    'B_win_by_Decision_Split': [0],
    'B_win_by_Decision_Unanimous': [0],
    'B_win_by_KO/TKO': [19], 
    'B_win_by_Submission': [1],
    'B_wins': [20],
    'B_Weight_lbs': [185],
    'R_win_by_Decision_Split': [2],
    'R_win_by_Decision_Unanimous': [10],
    'R_win_by_KO/TKO': [11],
    'R_win_by_Submission': [4],
    'R_wins': [28],
    'R_Weight_lbs': [185],
    'R_age': [32],
    'B_age': [30],
    'lose_streak_dif': [0],
    'win_streak_dif': [-8], # Dricus had a massive 9-fight win streak
    'longest_win_streak_dif': [-3], 
    'win_dif': [8],
    'loss_dif': [3], # Strickland had more experience but more losses
    'total_round_dif': [24], 
    'total_title_bout_dif': [1], # Strickland was the champ, Dricus's first title bout
    'ko_dif': [-8],
    'sub_dif': [3],
    'height_dif': [1], # 6'1" vs 6'0"
    'reach_dif': [0], # Both have a 76" reach
    'age_dif': [2],
    'sig_str_dif': [-0.87], # Du Plessis actually had higher volume (6.95 vs 6.08)
    'avg_sub_att_dif': [-0.8],
    'avg_td_dif': [-2.72], # Dricus is a much heavier grappler (3.72 vs 1.00)
    'constant_1': [1]
}

X_tossup = pd.DataFrame(strickland_vs_dricus)

# Predict!
prob = model_fit.predict_proba(X_tossup)
winner = "STRICKLAND (Red)" if prob[0][1] > 0.5 else "DU PLESSIS (Blue)"
print(f"Predicted Winner: {winner}")
print(f"Confidence: {max(prob[0]):.2%}")
```

This was a controversial win but the model predicted it right, to wrap this up lets check the prediction for this weekend's championship bout Volkanovski vs Lopes

```{python}
import pandas as pd

# Stats for Alexander Volkanovski (Red) vs Diego Lopes (Blue) - UFC 325
volk_vs_lopes_rematch = {
    'no_of_rounds': [5],
    'B_win_by_Decision_Split': [0],
    'B_win_by_Decision_Unanimous': [3],
    'B_win_by_KO/TKO': [3],   # Includes recent win over Jean Silva
    'B_win_by_Submission': [1],
    'B_wins': [27],
    'B_Weight_lbs': [145],
    'R_win_by_Decision_Split': [1],
    'R_win_by_Decision_Unanimous': [11],
    'R_win_by_KO/TKO': [13],
    'R_win_by_Submission': [3],
    'R_wins': [27],
    'R_Weight_lbs': [145],
    'R_age': [37],
    'B_age': [31],
    'lose_streak_dif': [0],
    'win_streak_dif': [-1], # Lopes is on a 1-win streak, Volk technically has 1 win (their last fight)
    'longest_win_streak_dif': [10], # Volk's legendary 12-fight UFC streak
    'win_dif': [0], # Both sit at 27 pro wins
    'loss_dif': [-3], # Volk has 4 losses, Lopes has 7
    'total_round_dif': [25], # Volk has far more 5-round experience
    'total_title_bout_dif': [14], # Volk has 15 title fights, Lopes has 1
    'ko_dif': [10],
    'sub_dif': [2],
    'height_dif': [-5], # 5'6" vs 5'11" (Huge height gap)
    'reach_dif': [-1], # 71" vs 72"
    'age_dif': [6],
    'sig_str_dif': [2.08], # 6.18 vs 4.10 (Landed per minute)
    'avg_sub_att_dif': [-1.5],
    'avg_td_dif': [0.88], # 1.67 vs 0.79 (Takedowns per 15 min)
    'constant_1': [1]
}

X_rematch = pd.DataFrame(volk_vs_lopes_rematch)

# Run the prediction
prediction = model_fit.predict(X_rematch)
probs = model_fit.predict_proba(X_rematch)

winner = "VOLKANOVSKI (Red)" if prediction[0] == 1 else "LOPES (Blue)"
print(f"Predicted Winner: {winner}")
print(f"Confidence: {probs[0][prediction[0]]:.2%}")
```

I'm a diego lopes fan so now I hope my model is wrong on this one, but the predicted outcome is similar to what the mainstream opinion is as Volkanovski is considered one of the greatest to ever do it and very experienced.